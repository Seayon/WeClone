# WeClone 子文件夹并行处理功能使用说明

## 功能概述

WeClone 现在支持在处理CSV子文件夹时指定并行度，可以同时处理多个子文件夹，并且会在每个子文件夹处理完后保存中间结果，支持中断后恢复处理。

## 新增命令行参数

`make-dataset` 命令现在支持以下参数：

- `--parallel` / `-p`: 指定并行处理的子文件夹数量（默认: 1）

## 工作原理

### 1. 子文件夹并行处理
程序会扫描 `./dataset/csv` 目录下的所有子文件夹，每个子文件夹包含一个用户或群组的聊天记录CSV文件。

### 2. 中间结果保存
每个子文件夹处理完成后，结果会立即保存到 `./dataset/temp_results/` 目录中，文件名为 `{子文件夹名}.json`。

### 3. 进度记录
已处理的子文件夹会记录在 `./dataset/processed_folders.txt` 文件中，程序重启时会自动跳过已处理的文件夹。

### 4. 结果合并
所有子文件夹处理完成后，程序会自动合并所有中间结果为最终的 `./dataset/res_csv/sft/sft-my.json` 文件。

## 使用方法

### 1. 默认单线程处理
```bash
python -m weclone make-dataset
```

### 2. 指定并行度
```bash
# 使用4个线程并行处理
python -m weclone make-dataset --parallel 4

# 简写形式
python -m weclone make-dataset -p 8
```

## 目录结构要求

```
WeClone/
├── dataset/
│   ├── csv/
│   │   ├── user1/              # 用户1的聊天记录CSV文件
│   │   │   ├── wxid_xxx_0_5000.csv
│   │   │   ├── wxid_xxx_5000_10000.csv
│   │   │   └── ...
│   │   ├── user2/              # 用户2的聊天记录CSV文件
│   │   │   ├── wxid_yyy_0_3000.csv
│   │   │   └── ...
│   │   └── group1/             # 群组1的聊天记录CSV文件
│   │       ├── chatroom_zzz_0_8000.csv
│   │       └── ...
│   ├── temp_results/           # 中间结果目录（自动创建）
│   │   ├── user1.json
│   │   ├── user2.json
│   │   └── group1.json
│   ├── processed_folders.txt   # 已处理文件夹记录（自动创建）
│   └── res_csv/
│       └── sft/
│           └── sft-my.json     # 最终合并结果
```

## 并行度设置建议

### CPU核心数与并行度关系

1. **单核CPU**: 虽然只有1个核心，但仍可设置并行度为2-4，因为CSV文件读写是I/O密集型任务，当一个线程等待文件读写时，CPU可以切换到其他线程。

2. **多核CPU**: 建议并行度不超过CPU核心数的2倍，例如：
   - 4核CPU: 建议并行度 4-8
   - 8核CPU: 建议并行度 8-16

3. **内存考虑**: 每个线程会加载一个子文件夹的所有数据到内存，如果子文件夹很大，需要适当降低并行度。

## 中断恢复功能

### 如何工作
- 程序启动时会检查 `./dataset/processed_folders.txt` 文件
- 已记录的子文件夹会被跳过，只处理未完成的子文件夹
- 中间结果保存在 `./dataset/temp_results/` 目录中

### 重新开始处理
如果需要重新处理所有文件夹，删除以下文件：
```bash
rm ./dataset/processed_folders.txt
rm -rf ./dataset/temp_results/
```

## 实际使用示例

### 场景1: 处理多个用户的聊天记录
```bash
# 假设有10个用户文件夹，使用4个线程并行处理
python -m weclone make-dataset -p 4
```

### 场景2: 大量数据处理
```bash
# 对于大量数据，可以使用更高的并行度
python -m weclone make-dataset -p 8
```

### 场景3: 内存受限环境
```bash
# 在内存较小的环境中，使用较低的并行度
python -m weclone make-dataset -p 2
```

## 监控处理进度

### 查看已处理的文件夹
```bash
cat ./dataset/processed_folders.txt
```

### 查看中间结果
```bash
ls -la ./dataset/temp_results/
```

### 监控系统资源
```bash
# 监控CPU和内存使用
htop

# 监控磁盘I/O
iotop
```

## 注意事项

1. **线程安全**: 程序使用线程锁确保文件操作的安全性
2. **错误处理**: 单个子文件夹处理失败不会影响其他子文件夹
3. **磁盘空间**: 确保有足够的磁盘空间存储中间结果
4. **内存使用**: 并行度越高，内存使用越多
5. **文件命名**: 子文件夹名称不能包含特殊字符

## 故障排除

### 进程被killed
如果遇到进程被killed的情况：
1. 降低并行度 (`-p 1` 或 `-p 2`)
2. 检查系统内存使用情况
3. 检查磁盘空间是否充足

### 部分文件夹处理失败
1. 查看日志输出中的错误信息
2. 检查CSV文件格式是否正确
3. 确认文件权限是否正确

### 中断后无法恢复
1. 检查 `./dataset/processed_folders.txt` 文件是否存在
2. 检查 `./dataset/temp_results/` 目录中的文件
3. 如果文件损坏，删除相关记录重新处理

## 查看帮助信息

```bash
python -m weclone make-dataset --help